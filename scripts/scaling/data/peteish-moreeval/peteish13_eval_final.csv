throughput/total_tokens,eval/c4_en-validation/CrossEntropyLoss,eval/dolma_books-validation/CrossEntropyLoss,eval/dolma_common-crawl-validation/CrossEntropyLoss,eval/dolma_pes2o-validation/CrossEntropyLoss,eval/dolma_reddit-validation/CrossEntropyLoss,eval/dolma_stack-validation/CrossEntropyLoss,eval/dolma_wiki-validation/CrossEntropyLoss,eval/ice-validation/CrossEntropyLoss,eval/m2d2_s2orc-validation/CrossEntropyLoss,eval/pile-validation/CrossEntropyLoss,eval/wikitext_103-validation/CrossEntropyLoss,eval/downstream_bpb/mmlu_stem_val_rc_5shot_bpb,eval/downstream_bpb/mmlu_humanities_val_rc_5shot_bpb,eval/downstream_bpb/mmlu_social_sciences_val_rc_5shot_bpb,eval/downstream_bpb/mmlu_other_val_rc_5shot_bpb,eval/downstream_bpb/mmlu_stem_test_rc_5shot_bpb,eval/downstream_bpb/mmlu_humanities_test_rc_5shot_bpb,eval/downstream_bpb/mmlu_social_sciences_test_rc_5shot_bpb,eval/downstream_bpb/mmlu_other_test_rc_5shot_bpb,eval/downstream_bpb/hellaswag_val_rc_5shot_bpb,eval/downstream_bpb/arc_easy_val_rc_5shot_bpb,eval/downstream_bpb/arc_easy_test_rc_5shot_bpb,eval/downstream_bpb/arc_challenge_val_rc_5shot_bpb,eval/downstream_bpb/arc_challenge_test_rc_5shot_bpb,eval/downstream_bpb/boolq_val_rc_5shot_bpb,eval/downstream_bpb/csqa_val_rc_5shot_bpb,eval/downstream_bpb/openbookqa_val_rc_5shot_bpb,eval/downstream_bpb/openbookqa_test_rc_5shot_bpb,eval/downstream_bpb/piqa_val_rc_5shot_bpb,eval/downstream_bpb/socialiqa_val_rc_5shot_bpb,eval/downstream_bpb/winogrande_val_rc_5shot_bpb,eval/downstream/mmlu_stem_val_rc_5shot_len_norm,eval/downstream/mmlu_humanities_val_rc_5shot_len_norm,eval/downstream/mmlu_social_sciences_val_rc_5shot_len_norm,eval/downstream/mmlu_other_val_rc_5shot_len_norm,eval/downstream/mmlu_stem_test_rc_5shot_len_norm,eval/downstream/mmlu_humanities_test_rc_5shot_len_norm,eval/downstream/mmlu_social_sciences_test_rc_5shot_len_norm,eval/downstream/mmlu_other_test_rc_5shot_len_norm,eval/downstream/hellaswag_val_rc_5shot_len_norm,eval/downstream/arc_easy_val_rc_5shot_len_norm,eval/downstream/arc_easy_test_rc_5shot_len_norm,eval/downstream/arc_challenge_val_rc_5shot_len_norm,eval/downstream/arc_challenge_test_rc_5shot_len_norm,eval/downstream/boolq_val_rc_5shot_acc,eval/downstream/csqa_val_rc_5shot_len_norm,eval/downstream/openbookqa_val_rc_5shot_len_norm,eval/downstream/openbookqa_test_rc_5shot_len_norm,eval/downstream/piqa_val_rc_5shot_len_norm,eval/downstream/socialiqa_val_rc_5shot_len_norm,eval/downstream/winogrande_val_rc_5shot_len_norm,eval/downstream/mmlu_stem_val_mc_5shot_len_norm,eval/downstream/mmlu_humanities_val_mc_5shot_len_norm,eval/downstream/mmlu_social_sciences_val_mc_5shot_len_norm,eval/downstream/mmlu_other_val_mc_5shot_len_norm,eval/downstream/mmlu_stem_test_mc_5shot_len_norm,eval/downstream/mmlu_humanities_test_mc_5shot_len_norm,eval/downstream/mmlu_social_sciences_test_mc_5shot_len_norm,eval/downstream/mmlu_other_test_mc_5shot_len_norm,eval/downstream/hellaswag_val_mc_5shot_acc,eval/downstream/arc_easy_val_mc_5shot_acc,eval/downstream/arc_easy_test_mc_5shot_acc,eval/downstream/arc_challenge_val_mc_5shot_acc,eval/downstream/arc_challenge_test_mc_5shot_acc,eval/downstream/boolq_val_mc_5shot_acc,eval/downstream/csqa_val_mc_5shot_acc,eval/downstream/openbookqa_val_mc_5shot_acc,eval/downstream/openbookqa_test_mc_5shot_acc,eval/downstream/piqa_val_mc_5shot_acc,eval/downstream/socialiqa_val_mc_5shot_acc,eval/downstream/winogrande_val_mc_5shot_acc,eval/downstream_soft/mmlu_stem_val_rc_5shot_soft,eval/downstream_soft/mmlu_humanities_val_rc_5shot_soft,eval/downstream_soft/mmlu_social_sciences_val_rc_5shot_soft,eval/downstream_soft/mmlu_other_val_rc_5shot_soft,eval/downstream_soft/mmlu_stem_test_rc_5shot_soft,eval/downstream_soft/mmlu_humanities_test_rc_5shot_soft,eval/downstream_soft/mmlu_social_sciences_test_rc_5shot_soft,eval/downstream_soft/mmlu_other_test_rc_5shot_soft,eval/downstream_soft/hellaswag_val_rc_5shot_soft,eval/downstream_soft/arc_easy_val_rc_5shot_soft,eval/downstream_soft/arc_easy_test_rc_5shot_soft,eval/downstream_soft/arc_challenge_val_rc_5shot_soft,eval/downstream_soft/arc_challenge_test_rc_5shot_soft,eval/downstream_soft/boolq_val_rc_5shot_soft,eval/downstream_soft/csqa_val_rc_5shot_soft,eval/downstream_soft/openbookqa_val_rc_5shot_soft,eval/downstream_soft/openbookqa_test_rc_5shot_soft,eval/downstream_soft/piqa_val_rc_5shot_soft,eval/downstream_soft/socialiqa_val_rc_5shot_soft,eval/downstream_soft/winogrande_val_rc_5shot_soft,eval/downstream_soft_log/mmlu_stem_val_rc_5shot_soft_log,eval/downstream_soft_log/mmlu_humanities_val_rc_5shot_soft_log,eval/downstream_soft_log/mmlu_social_sciences_val_rc_5shot_soft_log,eval/downstream_soft_log/mmlu_other_val_rc_5shot_soft_log,eval/downstream_soft_log/mmlu_stem_test_rc_5shot_soft_log,eval/downstream_soft_log/mmlu_humanities_test_rc_5shot_soft_log,eval/downstream_soft_log/mmlu_social_sciences_test_rc_5shot_soft_log,eval/downstream_soft_log/mmlu_other_test_rc_5shot_soft_log,eval/downstream_soft_log/hellaswag_val_rc_5shot_soft_log,eval/downstream_soft_log/arc_easy_val_rc_5shot_soft_log,eval/downstream_soft_log/arc_easy_test_rc_5shot_soft_log,eval/downstream_soft_log/arc_challenge_val_rc_5shot_soft_log,eval/downstream_soft_log/arc_challenge_test_rc_5shot_soft_log,eval/downstream_soft_log/boolq_val_rc_5shot_soft_log,eval/downstream_soft_log/csqa_val_rc_5shot_soft_log,eval/downstream_soft_log/openbookqa_val_rc_5shot_soft_log,eval/downstream_soft_log/openbookqa_test_rc_5shot_soft_log,eval/downstream_soft_log/piqa_val_rc_5shot_soft_log,eval/downstream_soft_log/socialiqa_val_rc_5shot_soft_log,eval/downstream_soft_log/winogrande_val_rc_5shot_soft_log,learning_rate_peak,batch_size_in_tokens
5000088518656,2.437581777572632,2.230504274368286,2.542837619781494,1.8158036470413208,2.755523920059204,1.021446943283081,1.94672691822052,2.409085512161255,2.731372594833374,1.8048807382583618,1.9020196199417114,1.2684375047683716,0.5266556143760681,0.6070871949195862,0.8257836103439331,1.1896381378173828,0.514882504940033,0.6392757892608643,0.7950442433357239,0.6599351167678833,0.5304761528968811,0.5153260827064514,0.6583492755889893,0.720653772354126,0.2535075545310974,0.8068247437477112,1.2538584470748901,1.2574141025543213,0.9010409712791443,0.9551135897636414,1.5027871131896973,0.42990654706954956,0.4671814739704132,0.5459940433502197,0.6169013977050781,0.4715043008327484,0.4733262360095978,0.554111123085022,0.5749537348747253,0.8336984515190125,0.8491228222846985,0.869528591632843,0.6354514956474304,0.6296928524971008,0.849235475063324,0.7420147657394409,0.5059999823570251,0.4779999852180481,0.8291621208190918,0.626919150352478,0.7932122945785522,0.4704049825668335,0.5579150319099426,0.7626112699508667,0.7211267352104187,0.5238568782806396,0.5738576054573059,0.748131275177002,0.6890808343887329,0.7761402130126953,0.9280701875686646,0.9162458181381226,0.8093645572662354,0.8003413081169128,0.8504587411880493,0.7436527609825134,0.765999972820282,0.7919999957084656,0.8253536224365234,0.71033775806427,0.5966851115226746,0.2990688383579254,0.27353277802467346,0.2860105335712433,0.3283822238445282,0.305265337228775,0.2749013900756836,0.2895585298538208,0.3238706886768341,0.29746466875076294,0.35227906703948975,0.3610498607158661,0.29967671632766724,0.3018450140953064,0.7076819539070129,0.36497795581817627,0.3000553250312805,0.30908575654029846,0.5243481397628784,0.39574843645095825,0.5248233079910278,-1.2952691316604614,-1.3216735124588013,-1.2771551609039307,-1.1808459758758545,-1.2760827541351318,-1.3136413097381592,-1.2688167095184326,-1.1886180639266968,-1.217405915260315,-1.0741069316864014,-1.052175760269165,-1.2311862707138062,-1.2290892601013184,-0.3950313329696655,-1.072838306427002,-1.2639936208724976,-1.235004186630249,-0.6491997241973877,-0.9580450057983398,-0.6475601196289062,0.0003,8388608
