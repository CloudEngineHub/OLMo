_step,eval/c4_en-validation/CrossEntropyLoss,eval/dolma_books-validation/CrossEntropyLoss,eval/dolma_common-crawl-validation/CrossEntropyLoss,eval/dolma_pes2o-validation/CrossEntropyLoss,eval/dolma_reddit-validation/CrossEntropyLoss,eval/dolma_stack-validation/CrossEntropyLoss,eval/dolma_wiki-validation/CrossEntropyLoss,eval/ice-validation/CrossEntropyLoss,eval/m2d2_s2orc-validation/CrossEntropyLoss,eval/pile-validation/CrossEntropyLoss,eval/wikitext_103-validation/CrossEntropyLoss,eval/downstream_bpb/mmlu_stem_val_rc_5shot_bpb,eval/downstream_bpb/mmlu_humanities_val_rc_5shot_bpb,eval/downstream_bpb/mmlu_social_sciences_val_rc_5shot_bpb,eval/downstream_bpb/mmlu_other_val_rc_5shot_bpb,eval/downstream_bpb/mmlu_stem_test_rc_5shot_bpb,eval/downstream_bpb/mmlu_humanities_test_rc_5shot_bpb,eval/downstream_bpb/mmlu_social_sciences_test_rc_5shot_bpb,eval/downstream_bpb/mmlu_other_test_rc_5shot_bpb,eval/downstream_bpb/hellaswag_val_rc_5shot_bpb,eval/downstream_bpb/arc_easy_val_rc_5shot_bpb,eval/downstream_bpb/arc_easy_test_rc_5shot_bpb,eval/downstream_bpb/arc_challenge_val_rc_5shot_bpb,eval/downstream_bpb/arc_challenge_test_rc_5shot_bpb,eval/downstream_bpb/boolq_val_rc_5shot_bpb,eval/downstream_bpb/csqa_val_rc_5shot_bpb,eval/downstream_bpb/openbookqa_val_rc_5shot_bpb,eval/downstream_bpb/openbookqa_test_rc_5shot_bpb,eval/downstream_bpb/piqa_val_rc_5shot_bpb,eval/downstream_bpb/socialiqa_val_rc_5shot_bpb,eval/downstream_bpb/winogrande_val_rc_5shot_bpb,eval/downstream/mmlu_stem_val_rc_5shot_len_norm,eval/downstream/mmlu_humanities_val_rc_5shot_len_norm,eval/downstream/mmlu_social_sciences_val_rc_5shot_len_norm,eval/downstream/mmlu_other_val_rc_5shot_len_norm,eval/downstream/mmlu_stem_test_rc_5shot_len_norm,eval/downstream/mmlu_humanities_test_rc_5shot_len_norm,eval/downstream/mmlu_social_sciences_test_rc_5shot_len_norm,eval/downstream/mmlu_other_test_rc_5shot_len_norm,eval/downstream/hellaswag_val_rc_5shot_len_norm,eval/downstream/arc_easy_val_rc_5shot_len_norm,eval/downstream/arc_easy_test_rc_5shot_len_norm,eval/downstream/arc_challenge_val_rc_5shot_len_norm,eval/downstream/arc_challenge_test_rc_5shot_len_norm,eval/downstream/boolq_val_rc_5shot_acc,eval/downstream/csqa_val_rc_5shot_len_norm,eval/downstream/openbookqa_val_rc_5shot_len_norm,eval/downstream/openbookqa_test_rc_5shot_len_norm,eval/downstream/piqa_val_rc_5shot_len_norm,eval/downstream/socialiqa_val_rc_5shot_len_norm,eval/downstream/winogrande_val_rc_5shot_len_norm,eval/downstream/mmlu_stem_val_mc_5shot_len_norm,eval/downstream/mmlu_humanities_val_mc_5shot_len_norm,eval/downstream/mmlu_social_sciences_val_mc_5shot_len_norm,eval/downstream/mmlu_other_val_mc_5shot_len_norm,eval/downstream/mmlu_stem_test_mc_5shot_len_norm,eval/downstream/mmlu_humanities_test_mc_5shot_len_norm,eval/downstream/mmlu_social_sciences_test_mc_5shot_len_norm,eval/downstream/mmlu_other_test_mc_5shot_len_norm,eval/downstream/hellaswag_val_mc_5shot_acc,eval/downstream/arc_easy_val_mc_5shot_acc,eval/downstream/arc_easy_test_mc_5shot_acc,eval/downstream/arc_challenge_val_mc_5shot_acc,eval/downstream/arc_challenge_test_mc_5shot_acc,eval/downstream/boolq_val_mc_5shot_acc,eval/downstream/csqa_val_mc_5shot_acc,eval/downstream/openbookqa_val_mc_5shot_acc,eval/downstream/openbookqa_test_mc_5shot_acc,eval/downstream/piqa_val_mc_5shot_acc,eval/downstream/socialiqa_val_mc_5shot_acc,eval/downstream/winogrande_val_mc_5shot_acc,eval/downstream_soft/mmlu_stem_val_rc_5shot_soft,eval/downstream_soft/mmlu_humanities_val_rc_5shot_soft,eval/downstream_soft/mmlu_social_sciences_val_rc_5shot_soft,eval/downstream_soft/mmlu_other_val_rc_5shot_soft,eval/downstream_soft/mmlu_stem_test_rc_5shot_soft,eval/downstream_soft/mmlu_humanities_test_rc_5shot_soft,eval/downstream_soft/mmlu_social_sciences_test_rc_5shot_soft,eval/downstream_soft/mmlu_other_test_rc_5shot_soft,eval/downstream_soft/hellaswag_val_rc_5shot_soft,eval/downstream_soft/arc_easy_val_rc_5shot_soft,eval/downstream_soft/arc_easy_test_rc_5shot_soft,eval/downstream_soft/arc_challenge_val_rc_5shot_soft,eval/downstream_soft/arc_challenge_test_rc_5shot_soft,eval/downstream_soft/boolq_val_rc_5shot_soft,eval/downstream_soft/csqa_val_rc_5shot_soft,eval/downstream_soft/openbookqa_val_rc_5shot_soft,eval/downstream_soft/openbookqa_test_rc_5shot_soft,eval/downstream_soft/piqa_val_rc_5shot_soft,eval/downstream_soft/socialiqa_val_rc_5shot_soft,eval/downstream_soft/winogrande_val_rc_5shot_soft,eval/downstream_soft_log/mmlu_stem_val_rc_5shot_soft_log,eval/downstream_soft_log/mmlu_humanities_val_rc_5shot_soft_log,eval/downstream_soft_log/mmlu_social_sciences_val_rc_5shot_soft_log,eval/downstream_soft_log/mmlu_other_val_rc_5shot_soft_log,eval/downstream_soft_log/mmlu_stem_test_rc_5shot_soft_log,eval/downstream_soft_log/mmlu_humanities_test_rc_5shot_soft_log,eval/downstream_soft_log/mmlu_social_sciences_test_rc_5shot_soft_log,eval/downstream_soft_log/mmlu_other_test_rc_5shot_soft_log,eval/downstream_soft_log/hellaswag_val_rc_5shot_soft_log,eval/downstream_soft_log/arc_easy_val_rc_5shot_soft_log,eval/downstream_soft_log/arc_easy_test_rc_5shot_soft_log,eval/downstream_soft_log/arc_challenge_val_rc_5shot_soft_log,eval/downstream_soft_log/arc_challenge_test_rc_5shot_soft_log,eval/downstream_soft_log/boolq_val_rc_5shot_soft_log,eval/downstream_soft_log/csqa_val_rc_5shot_soft_log,eval/downstream_soft_log/openbookqa_val_rc_5shot_soft_log,eval/downstream_soft_log/openbookqa_test_rc_5shot_soft_log,eval/downstream_soft_log/piqa_val_rc_5shot_soft_log,eval/downstream_soft_log/socialiqa_val_rc_5shot_soft_log,eval/downstream_soft_log/winogrande_val_rc_5shot_soft_log,learning_rate_peak,batch_size_in_tokens
1907359,2.777465343475342,2.6479222774505615,2.8912131786346436,2.098891019821167,3.044100761413574,1.2833447456359863,2.3179237842559814,2.741729974746704,3.0630900859832764,2.1325533390045166,2.321869134902954,1.6239001750946045,0.6673868894577026,0.765968382358551,1.0171889066696167,1.5594393014907837,0.6483531594276428,0.8039936423301697,0.9769769906997681,0.7452888488769531,0.6647458672523499,0.6660555601119995,0.8051725029945374,0.8916786313056946,0.39210522174835205,0.9674152135848999,1.3471299409866333,1.346285104751587,0.9894012808799744,1.061143159866333,1.4747843742370605,0.3302180767059326,0.30308881402015686,0.40652820467948914,0.47887325286865234,0.3396289050579071,0.3334750235080719,0.4101397395133972,0.45619988441467285,0.679745078086853,0.6877192854881287,0.7272727489471436,0.44481605291366577,0.4266211688518524,0.6727828979492188,0.6560196280479431,0.38600000739097595,0.3919999897480011,0.7671381831169128,0.5435004830360413,0.6771901845932007,0.2554517090320587,0.2528957426548004,0.2640949487686157,0.2704225480556488,0.2571239173412323,0.2510095536708832,0.2859928607940674,0.2785317599773407,0.2509460151195526,0.2824561297893524,0.26178452372550964,0.260869562625885,0.2619453966617584,0.49480122327804565,0.20884521305561066,0.27000001072883606,0.26600000262260437,0.5054407119750977,0.33469805121421814,0.5003946423530579,0.26785993576049805,0.2590025067329407,0.265961617231369,0.2957727313041687,0.2640996277332306,0.2611326277256012,0.2690352499485016,0.28885558247566223,0.28256547451019287,0.3129780888557434,0.31828218698501587,0.2711487114429474,0.2707429528236389,0.5888914465904236,0.3259737491607666,0.2765268385410309,0.28352120518684387,0.5167194604873657,0.378345251083374,0.5117824077606201,-1.3812718391418457,-1.3705750703811646,-1.3485437631607056,-1.2740572690963745,-1.3974248170852661,-1.3604037761688232,-1.337322473526001,-1.2883754968643188,-1.2692326307296753,-1.1842960119247437,-1.1707303524017334,-1.3235520124435425,-1.3278324604034424,-0.5777207016944885,-1.1885653734207153,-1.3391765356063843,-1.312188982963562,-0.6639573574066162,-1.004286766052246,-0.6719348430633545,0.0004,2097152
